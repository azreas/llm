{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23160e39-87be-4f55-9cda-8156b3fe7050",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4885229348d74ca083549bd2351fab62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from peft import PeftModel\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/opt/cache/modelscope/hub/ZhipuAI/chatglm3-6b\",trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"/opt/cache/modelscope/hub/ZhipuAI/chatglm3-6b\",trust_remote_code=True).half().cuda()\n",
    "# model = model.eval()\n",
    "# print(model)\n",
    "\n",
    "new_model = PeftModel.from_pretrained(\n",
    "            model,\n",
    "            \"/opt/data/chatglm3-6b/customer_sft_1000_all_m\",\n",
    "            device_map='auto'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6b4cab-5889-40bb-becf-5ebfa6704233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response, history = new_model.chat(tokenizer, \"能不能靠谱点\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"人工客服\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"今天发明天能收到吗\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"发货后到广州预计几天左右能到\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"新疆发货不\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"新疆发货不\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"能发韵达吗\", history=[])\n",
    "# print('------')\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8765def6-a04e-43b6-9d53-505990bf0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response, history = new_model.chat(tokenizer, \"服务一点不靠谱\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"转人工客服\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"今天发货的话明天能收到吗\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"发成都多久能收到\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"台湾发货不\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"西藏发货不\", history=[])\n",
    "# print('------')\n",
    "# print(response)\n",
    "# response, history = new_model.chat(tokenizer, \"可以发其他快递吗\", history=[])\n",
    "# print('------')\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7124ce5a-76be-4653-8ea9-1316edf31b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "轩宝，非常理解您可能是因为某些快递不方便，但为了保证发货速度，咱们是系统自动配货哦，无法指定快递，我们合作的快递到货也是挺快的哟，还望您多多谅解呢\n",
      "------\n",
      "轩宝，非常理解您可能是因为某些快递不方便，但为了保证发货速度，咱们是系统自动配货哦，无法指定快递，我们合作的快递到货也是挺快的哟，还望您多多谅解呢\n",
      "------\n",
      "轩宝，咱家目前书籍都是仓库根据库存就近发货，库存充足情况下尽量会按照订单一起发货的，具体以仓库发货为准哟，请您理解♡\n",
      "------\n",
      "您好，大陆地区我们都可以发货哦，海外和港澳台的读者可以将地址留为中转仓，再由中转仓转到海外地址哦\n",
      "------\n",
      "轩宝，您放心，我们店铺的商品都会在仓库发货的，请您放心购买哦~\n",
      "------\n",
      "不好意思，咱们家是仓库根据库存就近发货。\n",
      "------\n",
      "不好意思，港澳台和海外只能发到集运仓，需要您自己联系转运呢\n"
     ]
    }
   ],
   "source": [
    "response, history = new_model.chat(tokenizer, \"能发潮州吗\", history=[])\n",
    "print('------')\n",
    "print(response)\n",
    "response, history = new_model.chat(tokenizer, \"能发申通吗\", history=[])\n",
    "print('------')\n",
    "print(response)\n",
    "response, history = new_model.chat(tokenizer, \"新竹发货不\", history=[])\n",
    "print('------')\n",
    "print(response)\n",
    "response, history = new_model.chat(tokenizer, \"高雄能发货？\", history=[])\n",
    "print('------')\n",
    "print(response)\n",
    "response, history = new_model.chat(tokenizer, \"能发东京吗\", history=[])\n",
    "print('------')\n",
    "print(response)\n",
    "response, history = new_model.chat(tokenizer, \"可以寄纽约吗\", history=[])\n",
    "print('------')\n",
    "print(response)\n",
    "response, history = new_model.chat(tokenizer, \"我在美国，可以发货吗\", history=[])\n",
    "print('------')\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
